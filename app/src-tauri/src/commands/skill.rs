use crate::db::Db;
use crate::types::SkillSummary;
use serde::Serialize;
use std::fs;
use std::path::Path;

#[tauri::command]
pub fn list_skills(
    workspace_path: String,
    db: tauri::State<'_, Db>,
) -> Result<Vec<SkillSummary>, String> {
    log::info!("[list_skills]");
    let conn = db.0.lock().map_err(|e| {
        log::error!("[list_skills] Failed to acquire DB lock: {}", e);
        e.to_string()
    })?;
    list_skills_inner(&workspace_path, &conn)
}

/// DB-primary skill listing. After reconciliation runs at startup, the DB is the
/// single source of truth. This function queries all `workflow_runs` from the DB,
/// batch-fetches tags, and builds a `SkillSummary` list. No filesystem scanning.
///
/// The `_workspace_path` parameter is retained for backward compatibility with the
/// Tauri command signature (the frontend still passes it), but is not used for
/// skill discovery.
fn list_skills_inner(
    _workspace_path: &str,
    conn: &rusqlite::Connection,
) -> Result<Vec<SkillSummary>, String> {
    // Query all workflow runs from the DB
    let runs = crate::db::list_all_workflow_runs(conn)?;

    // Batch-fetch tags for all skills
    let names: Vec<String> = runs.iter().map(|r| r.skill_name.clone()).collect();
    let tags_map = crate::db::get_tags_for_skills(conn, &names)?;

    // Build SkillSummary list from DB data
    let mut skills: Vec<SkillSummary> = runs
        .into_iter()
        .map(|run| {
            let tags = tags_map
                .get(&run.skill_name)
                .cloned()
                .unwrap_or_default();

            SkillSummary {
                name: run.skill_name,
                domain: Some(run.domain),
                current_step: Some(format!("Step {}", run.current_step)),
                status: Some(run.status),
                last_modified: Some(run.updated_at),
                tags,
                skill_type: Some(run.skill_type),
                author_login: run.author_login,
                author_avatar: run.author_avatar,
                display_name: run.display_name,
                intake_json: run.intake_json,
            }
        })
        .collect();

    // Sort by last_modified descending (most recent first)
    skills.sort_by(|a, b| b.last_modified.cmp(&a.last_modified));
    Ok(skills)
}

/// Returns skills that have completed their build (status = 'completed') and
/// have a SKILL.md on disk. These are eligible for the refine workflow.
#[tauri::command]
pub fn list_refinable_skills(
    workspace_path: String,
    db: tauri::State<'_, Db>,
) -> Result<Vec<SkillSummary>, String> {
    log::info!("[list_refinable_skills]");

    // Hold the DB lock only for DB reads; release before filesystem I/O.
    let (skills_path, completed) = {
        let conn = db.0.lock().map_err(|e| {
            log::error!("[list_refinable_skills] Failed to acquire DB lock: {}", e);
            e.to_string()
        })?;
        let settings = crate::db::read_settings(&conn).map_err(|e| {
            log::error!("[list_refinable_skills] Failed to read settings: {}", e);
            e
        })?;
        let skills_path = settings
            .skills_path
            .unwrap_or_else(|| workspace_path.clone());
        let all = list_skills_inner(&workspace_path, &conn)?;
        let completed: Vec<SkillSummary> = all
            .into_iter()
            .filter(|s| s.status.as_deref() == Some("completed"))
            .collect();
        (skills_path, completed)
    }; // conn lock released here

    // Filesystem existence checks happen outside the DB lock.
    Ok(filter_by_skill_md_exists(&skills_path, completed))
}

/// Filter completed skills to only those with a SKILL.md on disk.
/// Separated from DB access so the Tauri command can release the DB lock first.
fn filter_by_skill_md_exists(skills_path: &str, completed: Vec<SkillSummary>) -> Vec<SkillSummary> {
    completed
        .into_iter()
        .filter(|s| {
            Path::new(skills_path)
                .join(&s.name)
                .join("SKILL.md")
                .exists()
        })
        .collect()
}

/// Testable inner function: queries the DB for completed skills, then filters
/// by SKILL.md existence on disk. In production, the Tauri command splits these
/// two phases across a lock boundary; this function combines them for tests.
#[cfg(test)]
fn list_refinable_skills_inner(
    workspace_path: &str,
    skills_path: &str,
    conn: &rusqlite::Connection,
) -> Result<Vec<SkillSummary>, String> {
    let all = list_skills_inner(workspace_path, conn)?;
    let completed: Vec<SkillSummary> = all
        .into_iter()
        .filter(|s| s.status.as_deref() == Some("completed"))
        .collect();
    Ok(filter_by_skill_md_exists(skills_path, completed))
}

#[allow(clippy::too_many_arguments)]
#[tauri::command]
pub fn create_skill(
    app: tauri::AppHandle,
    workspace_path: String,
    name: String,
    domain: String,
    tags: Option<Vec<String>>,
    skill_type: Option<String>,
    intake_json: Option<String>,
    db: tauri::State<'_, Db>,
) -> Result<(), String> {
    log::info!("[create_skill] name={} domain={} skill_type={:?} tags={:?} intake={}", name, domain, skill_type, tags, intake_json.is_some());
    let conn = db.0.lock().ok();
    // Read settings from DB
    let settings = conn.as_deref().and_then(|c| crate::db::read_settings(c).ok());
    let skills_path = settings.as_ref().and_then(|s| s.skills_path.clone());

    // Require skills_path to be configured
    if skills_path.is_none() {
        return Err(
            "Skills output path is not configured. Please set it in Settings before creating skills."
                .to_string(),
        );
    }

    let author_login = settings.as_ref().and_then(|s| s.github_user_login.clone());
    let author_avatar = settings.as_ref().and_then(|s| s.github_user_avatar.clone());
    let app_version = app.config().version.clone().unwrap_or_default();
    create_skill_inner(
        &workspace_path,
        &name,
        &domain,
        tags.as_deref(),
        skill_type.as_deref(),
        conn.as_deref(),
        skills_path.as_deref(),
        author_login.as_deref(),
        author_avatar.as_deref(),
        &app_version,
        intake_json.as_deref(),
    )
}

#[allow(clippy::too_many_arguments)]
fn create_skill_inner(
    workspace_path: &str,
    name: &str,
    domain: &str,
    tags: Option<&[String]>,
    skill_type: Option<&str>,
    conn: Option<&rusqlite::Connection>,
    skills_path: Option<&str>,
    author_login: Option<&str>,
    author_avatar: Option<&str>,
    app_version: &str,
    intake_json: Option<&str>,
) -> Result<(), String> {
    // Check for collision in workspace_path (working directory)
    let base = Path::new(workspace_path).join(name);
    if base.exists() {
        return Err(format!(
            "Skill '{}' already exists in workspace directory ({})",
            name,
            base.display()
        ));
    }

    // Check for collision in skills_path (skill output directory)
    if let Some(sp) = skills_path {
        let skill_output = Path::new(sp).join(name);
        if skill_output.exists() {
            return Err(format!(
                "Skill '{}' already exists in skills output directory ({})",
                name,
                skill_output.display()
            ));
        }
    }

    if let Some(sp) = skills_path {
        // Workspace dir is a marker for reconcile; context lives in skills_path
        fs::create_dir_all(&base).map_err(|e| e.to_string())?;
        let skill_output = Path::new(sp).join(name);
        fs::create_dir_all(skill_output.join("context")).map_err(|e| e.to_string())?;
        fs::create_dir_all(skill_output.join("references")).map_err(|e| e.to_string())?;
    } else {
        // No skills_path — workspace holds everything including context
        fs::create_dir_all(base.join("context")).map_err(|e| e.to_string())?;
    }

    let skill_type = skill_type.unwrap_or("domain");

    if let Some(conn) = conn {
        crate::db::save_workflow_run(conn, name, domain, 0, "pending", skill_type)?;

        if let Some(tags) = tags {
            if !tags.is_empty() {
                crate::db::set_skill_tags(conn, name, tags)?;
            }
        }

        if let Some(login) = author_login {
            let _ = crate::db::set_skill_author(conn, name, login, author_avatar);
        }

        if let Some(ij) = intake_json {
            let _ = crate::db::set_skill_intake(conn, name, Some(ij));
        }
    }

    // Write .skill-builder manifest into the skill output directory
    if let Some(sp) = skills_path {
        let skill_output = Path::new(sp).join(name);
        if skill_output.exists() {
            if let Err(e) = super::github_push::write_manifest_file(&skill_output, author_login, app_version) {
                log::warn!("Failed to write .skill-builder manifest for '{}': {}", name, e);
            }
        }
    }

    // Auto-commit: skill created
    if let Some(sp) = skills_path {
        let msg = format!("{}: created", name);
        if let Err(e) = crate::git::commit_all(Path::new(sp), &msg) {
            log::warn!("Git auto-commit failed ({}): {}", msg, e);
        }
    }

    Ok(())
}

#[tauri::command]
pub fn delete_skill(
    workspace_path: String,
    name: String,
    db: tauri::State<'_, Db>,
) -> Result<(), String> {
    log::info!("[delete_skill] name={}", name);
    let conn = db.0.lock().map_err(|e| {
        log::error!("[delete_skill] Failed to acquire DB lock: {}", e);
        e.to_string()
    })?;
    // Read skills_path from settings DB
    let settings = crate::db::read_settings(&conn).ok();
    let skills_path = settings.as_ref().and_then(|s| s.skills_path.clone());

    // Require skills_path to be configured
    if skills_path.is_none() {
        return Err("Skills path not configured. Please set it in Settings.".to_string());
    }

    delete_skill_inner(
        &workspace_path,
        &name,
        Some(&conn),
        skills_path.as_deref(),
    )
}

fn delete_skill_inner(
    workspace_path: &str,
    name: &str,
    conn: Option<&rusqlite::Connection>,
    skills_path: Option<&str>,
) -> Result<(), String> {
    log::info!(
        "[delete_skill] skill={} workspace={} skills_path={:?}",
        name, workspace_path, skills_path
    );

    let base = Path::new(workspace_path).join(name);

    // Delete workspace working directory if it exists
    if base.exists() {
        // Verify this is inside the workspace path to prevent directory traversal
        let canonical_workspace = fs::canonicalize(workspace_path).map_err(|e| e.to_string())?;
        let canonical_target = fs::canonicalize(&base).map_err(|e| e.to_string())?;
        if !canonical_target.starts_with(&canonical_workspace) {
            return Err("Invalid skill path".to_string());
        }
        fs::remove_dir_all(&base).map_err(|e| e.to_string())?;
        log::info!("[delete_skill] deleted workspace dir {}", base.display());
    } else {
        log::info!("[delete_skill] workspace dir not found: {}", base.display());
    }

    // Delete skill output directory if skills_path is configured and directory exists
    if let Some(sp) = skills_path {
        let output_dir = Path::new(sp).join(name);
        if output_dir.exists() {
            fs::remove_dir_all(&output_dir).map_err(|e| {
                format!("Failed to delete skill output for '{}': {}", name, e)
            })?;
            log::info!("[delete_skill] deleted output dir {}", output_dir.display());
        } else {
            log::info!("[delete_skill] output dir not found: {}", output_dir.display());
        }
    } else {
        log::info!("[delete_skill] no skills_path configured, skipping output dir cleanup");
    }

    // Auto-commit: record the deletion in git
    if let Some(sp) = skills_path {
        let msg = format!("{}: deleted", name);
        if let Err(e) = crate::git::commit_all(Path::new(sp), &msg) {
            log::warn!("Git auto-commit failed ({}): {}", msg, e);
        }
    }

    // Full DB cleanup: workflow_run + steps + agent_runs + tags
    if let Some(conn) = conn {
        crate::db::delete_workflow_run(conn, name)?;
        log::info!("[delete_skill] DB records cleaned for {}", name);
    }

    Ok(())
}

#[tauri::command]
pub fn update_skill_tags(
    skill_name: String,
    tags: Vec<String>,
    db: tauri::State<'_, Db>,
) -> Result<(), String> {
    log::info!("[update_skill_tags] skill={} tags={:?}", skill_name, tags);
    let conn = db.0.lock().map_err(|e| {
        log::error!("[update_skill_tags] Failed to acquire DB lock: {}", e);
        e.to_string()
    })?;
    crate::db::set_skill_tags(&conn, &skill_name, &tags)
}

#[tauri::command]
pub fn get_all_tags(db: tauri::State<'_, Db>) -> Result<Vec<String>, String> {
    log::info!("[get_all_tags]");
    let conn = db.0.lock().map_err(|e| {
        log::error!("[get_all_tags] Failed to acquire DB lock: {}", e);
        e.to_string()
    })?;
    crate::db::get_all_tags(&conn)
}

#[tauri::command]
pub fn acquire_lock(
    skill_name: String,
    instance: tauri::State<'_, crate::InstanceInfo>,
    db: tauri::State<'_, Db>,
) -> Result<(), String> {
    log::info!("[acquire_lock] skill={}", skill_name);
    let conn = db.0.lock().map_err(|e| {
        log::error!("[acquire_lock] Failed to acquire DB lock: {}", e);
        e.to_string()
    })?;
    crate::db::acquire_skill_lock(&conn, &skill_name, &instance.id, instance.pid)
}

#[tauri::command]
pub fn release_lock(
    skill_name: String,
    instance: tauri::State<'_, crate::InstanceInfo>,
    db: tauri::State<'_, Db>,
) -> Result<(), String> {
    log::info!("[release_lock] skill={}", skill_name);
    let conn = db.0.lock().map_err(|e| {
        log::error!("[release_lock] Failed to acquire DB lock: {}", e);
        e.to_string()
    })?;
    crate::db::release_skill_lock(&conn, &skill_name, &instance.id)
}

#[tauri::command]
pub fn get_locked_skills(
    db: tauri::State<'_, Db>,
) -> Result<Vec<crate::types::SkillLock>, String> {
    log::info!("[get_locked_skills]");
    let conn = db.0.lock().map_err(|e| {
        log::error!("[get_locked_skills] Failed to acquire DB lock: {}", e);
        e.to_string()
    })?;
    crate::db::reclaim_dead_locks(&conn)?;
    crate::db::get_all_skill_locks(&conn)
}

#[tauri::command]
pub fn check_lock(
    skill_name: String,
    instance: tauri::State<'_, crate::InstanceInfo>,
    db: tauri::State<'_, Db>,
) -> Result<bool, String> {
    log::info!("[check_lock] skill={}", skill_name);
    let conn = db.0.lock().map_err(|e| {
        log::error!("[check_lock] Failed to acquire DB lock: {}", e);
        e.to_string()
    })?;
    match crate::db::get_skill_lock(&conn, &skill_name)? {
        Some(lock) => {
            if lock.instance_id == instance.id {
                Ok(false) // Locked by us, not locked from our perspective
            } else if !crate::db::check_pid_alive(lock.pid) {
                // Dead process — reclaim
                crate::db::release_skill_lock(&conn, &skill_name, &lock.instance_id)?;
                Ok(false)
            } else {
                Ok(true) // Locked by another live instance
            }
        }
        None => Ok(false),
    }
}

#[tauri::command]
pub fn update_skill_metadata(
    skill_name: String,
    domain: Option<String>,
    skill_type: Option<String>,
    tags: Option<Vec<String>>,
    intake_json: Option<String>,
    db: tauri::State<'_, Db>,
) -> Result<(), String> {
    log::info!("[update_skill_metadata] skill={} domain={:?} skill_type={:?} tags={:?} intake={}", skill_name, domain, skill_type, tags, intake_json.is_some());
    let conn = db.0.lock().map_err(|e| {
        log::error!("[update_skill_metadata] Failed to acquire DB lock: {}", e);
        e.to_string()
    })?;

    if let Some(d) = &domain {
        conn.execute(
            "UPDATE workflow_runs SET domain = ?2, updated_at = datetime('now') || 'Z' WHERE skill_name = ?1",
            rusqlite::params![skill_name, d],
        ).map_err(|e| {
            log::error!("[update_skill_metadata] Failed to update domain: {}", e);
            e.to_string()
        })?;
    }
    if let Some(st) = &skill_type {
        conn.execute(
            "UPDATE workflow_runs SET skill_type = ?2, updated_at = datetime('now') || 'Z' WHERE skill_name = ?1",
            rusqlite::params![skill_name, st],
        ).map_err(|e| {
            log::error!("[update_skill_metadata] Failed to update skill_type: {}", e);
            e.to_string()
        })?;
    }
    if let Some(tags) = &tags {
        crate::db::set_skill_tags(&conn, &skill_name, tags).map_err(|e| {
            log::error!("[update_skill_metadata] Failed to set tags: {}", e);
            e
        })?;
    }
    if let Some(ij) = &intake_json {
        crate::db::set_skill_intake(&conn, &skill_name, Some(ij)).map_err(|e| {
            log::error!("[update_skill_metadata] Failed to set intake_json: {}", e);
            e
        })?;
    }
    Ok(())
}

/// Validate kebab-case: lowercase alphanumeric segments separated by single hyphens.
fn is_valid_kebab(name: &str) -> bool {
    !name.is_empty()
        && !name.starts_with('-')
        && !name.ends_with('-')
        && !name.contains("--")
        && name.chars().all(|c| c.is_ascii_lowercase() || c.is_ascii_digit() || c == '-')
}

#[tauri::command]
pub fn rename_skill(
    old_name: String,
    new_name: String,
    workspace_path: String,
    db: tauri::State<'_, Db>,
) -> Result<(), String> {
    log::info!("[rename_skill] old={} new={}", old_name, new_name);

    if !is_valid_kebab(&new_name) {
        log::error!("[rename_skill] Invalid kebab-case name: {}", new_name);
        return Err("Skill name must be kebab-case (lowercase letters, numbers, hyphens)".to_string());
    }

    if old_name == new_name {
        return Ok(());
    }

    let conn = db.0.lock().map_err(|e| {
        log::error!("[rename_skill] Failed to acquire DB lock: {}", e);
        e.to_string()
    })?;

    // Read settings for skills_path
    let settings = crate::db::read_settings(&conn).ok();
    let skills_path = settings.as_ref().and_then(|s| s.skills_path.clone());

    rename_skill_inner(&old_name, &new_name, &workspace_path, &conn, skills_path.as_deref())?;

    // Auto-commit: skill renamed
    if let Some(ref sp) = skills_path {
        let msg = format!("{}: renamed from {}", new_name, old_name);
        if let Err(e) = crate::git::commit_all(Path::new(sp), &msg) {
            log::warn!("Git auto-commit failed ({}): {}", msg, e);
        }
    }

    Ok(())
}

fn rename_skill_inner(
    old_name: &str,
    new_name: &str,
    workspace_path: &str,
    conn: &rusqlite::Connection,
    skills_path: Option<&str>,
) -> Result<(), String> {
    // Check new name doesn't already exist
    let exists: bool = conn
        .query_row(
            "SELECT COUNT(*) > 0 FROM workflow_runs WHERE skill_name = ?1",
            rusqlite::params![new_name],
            |row| row.get(0),
        )
        .map_err(|e| e.to_string())?;
    if exists {
        log::error!("[rename_skill] Skill '{}' already exists", new_name);
        return Err(format!("Skill '{}' already exists", new_name));
    }

    // DB first, then disk — DB failures abort cleanly without leaving orphaned directories
    let tx_result = (|| -> Result<(), String> {
        conn.execute_batch("BEGIN TRANSACTION").map_err(|e| e.to_string())?;

        // workflow_runs: PK change — insert new, delete old
        conn.execute(
            "INSERT INTO workflow_runs (skill_name, domain, current_step, status, skill_type, created_at, updated_at, author_login, author_avatar, display_name, intake_json)
             SELECT ?2, domain, current_step, status, skill_type, created_at, datetime('now') || 'Z', author_login, author_avatar, display_name, intake_json
             FROM workflow_runs WHERE skill_name = ?1",
            rusqlite::params![old_name, new_name],
        ).map_err(|e| e.to_string())?;
        conn.execute(
            "DELETE FROM workflow_runs WHERE skill_name = ?1",
            rusqlite::params![old_name],
        ).map_err(|e| e.to_string())?;

        // workflow_steps
        conn.execute(
            "UPDATE workflow_steps SET skill_name = ?2 WHERE skill_name = ?1",
            rusqlite::params![old_name, new_name],
        ).map_err(|e| e.to_string())?;

        // skill_tags
        conn.execute(
            "UPDATE skill_tags SET skill_name = ?2 WHERE skill_name = ?1",
            rusqlite::params![old_name, new_name],
        ).map_err(|e| e.to_string())?;

        // agent_runs
        conn.execute(
            "UPDATE agent_runs SET skill_name = ?2 WHERE skill_name = ?1",
            rusqlite::params![old_name, new_name],
        ).map_err(|e| e.to_string())?;

        // workflow_artifacts
        conn.execute(
            "UPDATE workflow_artifacts SET skill_name = ?2 WHERE skill_name = ?1",
            rusqlite::params![old_name, new_name],
        ).map_err(|e| e.to_string())?;

        // skill_locks
        conn.execute(
            "UPDATE skill_locks SET skill_name = ?2 WHERE skill_name = ?1",
            rusqlite::params![old_name, new_name],
        ).map_err(|e| e.to_string())?;

        // workflow_sessions
        conn.execute(
            "UPDATE workflow_sessions SET skill_name = ?2 WHERE skill_name = ?1",
            rusqlite::params![old_name, new_name],
        ).map_err(|e| e.to_string())?;

        conn.execute_batch("COMMIT").map_err(|e| e.to_string())?;
        Ok(())
    })();

    if let Err(e) = tx_result {
        let _ = conn.execute_batch("ROLLBACK");
        log::error!("[rename_skill] DB transaction failed: {}", e);
        return Err(format!("Failed to rename skill in database: {}", e));
    }

    // Move directories on disk (DB already committed — if disk fails, reconciler can fix)
    let workspace_old = Path::new(workspace_path).join(old_name);
    let workspace_new = Path::new(workspace_path).join(new_name);
    if workspace_old.exists() {
        // Guard against directory traversal
        let canonical_workspace = fs::canonicalize(workspace_path).map_err(|e| e.to_string())?;
        let canonical_old = fs::canonicalize(&workspace_old).map_err(|e| e.to_string())?;
        if !canonical_old.starts_with(&canonical_workspace) {
            return Err("Invalid skill path".to_string());
        }
        fs::rename(&workspace_old, &workspace_new).map_err(|e| {
            log::error!("[rename_skill] Failed to rename workspace dir: {}", e);
            format!("Failed to rename workspace directory: {}", e)
        })?;
    }

    if let Some(sp) = skills_path {
        let skills_old = Path::new(sp).join(old_name);
        let skills_new = Path::new(sp).join(new_name);
        if skills_old.exists() {
            let canonical_skills = fs::canonicalize(sp).map_err(|e| e.to_string())?;
            let canonical_old = fs::canonicalize(&skills_old).map_err(|e| e.to_string())?;
            if !canonical_old.starts_with(&canonical_skills) {
                return Err("Invalid skill path".to_string());
            }
            fs::rename(&skills_old, &skills_new).map_err(|e| {
                log::error!("[rename_skill] Failed to rename skills dir: {}", e);
                // Rollback workspace rename to keep disk consistent
                if workspace_new.exists() {
                    let _ = fs::rename(&workspace_new, &workspace_old);
                }
                format!("Failed to rename skills directory: {}", e)
            })?;
        }
    }

    Ok(())
}

#[derive(Serialize)]
pub struct FieldSuggestions {
    pub domain: String,
    pub audience: String,
    pub challenges: String,
    pub scope: String,
    pub unique_setup: String,
    pub claude_mistakes: String,
}

#[tauri::command]
pub async fn generate_suggestions(
    skill_name: String,
    skill_type: String,
    industry: Option<String>,
    function_role: Option<String>,
    db: tauri::State<'_, Db>,
) -> Result<FieldSuggestions, String> {
    log::info!("[generate_suggestions] skill={} type={}", skill_name, skill_type);

    let api_key = {
        let conn = db.0.lock().map_err(|e| {
            log::error!("[generate_suggestions] Failed to acquire DB lock: {}", e);
            e.to_string()
        })?;
        let settings = crate::db::read_settings_hydrated(&conn).map_err(|e| {
            log::error!("[generate_suggestions] Failed to read settings: {}", e);
            e
        })?;
        settings
            .anthropic_api_key
            .ok_or_else(|| {
                log::error!("[generate_suggestions] API key not configured");
                "API key not configured".to_string()
            })?
    };

    let readable_name = skill_name.replace('-', " ");

    let context_parts: Vec<String> = [
        industry.as_deref().filter(|s| !s.is_empty()).map(|s| format!("Industry: {}", s)),
        function_role.as_deref().filter(|s| !s.is_empty()).map(|s| format!("Role: {}", s)),
    ]
    .into_iter()
    .flatten()
    .collect();

    let context = if context_parts.is_empty() {
        String::new()
    } else {
        format!(" User context: {}.", context_parts.join(", "))
    };

    let prompt = format!(
        "Given a Claude skill named \"{readable_name}\" of type \"{skill_type}\".{context}\n\n\
         Suggest brief values for these fields. Be specific and practical, not generic.\n\n\
         Respond in exactly this JSON format (no markdown, no extra text):\n\
         {{\"domain\": \"<1 sentence domain description>\", \
         \"audience\": \"<1 sentence target audience>\", \
         \"challenges\": \"<1 sentence key challenges>\", \
         \"scope\": \"<1 sentence scope>\", \
         \"unique_setup\": \"<1 sentence: what might make a typical {skill_type} setup for {readable_name} different from standard implementations?>\", \
         \"claude_mistakes\": \"<1 sentence: what does Claude typically get wrong when working with {readable_name} in the {skill_type} domain?>\"}}"
    );

    let client = reqwest::Client::builder()
        .timeout(std::time::Duration::from_secs(15))
        .build()
        .map_err(|e| e.to_string())?;
    let resp = client
        .post("https://api.anthropic.com/v1/messages")
        .header("x-api-key", &api_key)
        .header("anthropic-version", "2023-06-01")
        .header("content-type", "application/json")
        .body(
            serde_json::json!({
                "model": "claude-haiku-4-5-20251001",
                "max_tokens": 500,
                "messages": [{"role": "user", "content": prompt}]
            })
            .to_string(),
        )
        .send()
        .await
        .map_err(|e| {
            log::error!("[generate_suggestions] API request failed: {}", e);
            format!("API request failed: {}", e)
        })?;

    if !resp.status().is_success() {
        let status = resp.status().as_u16();
        let body = resp.text().await.unwrap_or_default();
        log::error!("[generate_suggestions] API error ({}): {}", status, body);
        return Err(format!("Anthropic API error ({})", status));
    }

    let body: serde_json::Value = resp.json().await.map_err(|e| {
        log::error!("[generate_suggestions] Failed to parse response JSON: {}", e);
        e.to_string()
    })?;
    let text = body["content"][0]["text"]
        .as_str()
        .ok_or_else(|| {
            log::error!("[generate_suggestions] No text in API response");
            "No text in API response".to_string()
        })?;

    // Parse the JSON response
    let suggestions: serde_json::Value =
        serde_json::from_str(text).map_err(|e| {
            log::error!("[generate_suggestions] Failed to parse suggestions: {}", e);
            format!("Failed to parse suggestions: {}", e)
        })?;

    let field = |key: &str| -> String {
        suggestions[key].as_str().unwrap_or("").to_string()
    };

    Ok(FieldSuggestions {
        domain: field("domain"),
        audience: field("audience"),
        challenges: field("challenges"),
        scope: field("scope"),
        unique_setup: field("unique_setup"),
        claude_mistakes: field("claude_mistakes"),
    })
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::commands::test_utils::create_test_db;
    use rusqlite::Connection;
    use tempfile::tempdir;

    // ===== list_skills_inner tests =====

    #[test]
    fn test_list_skills_db_primary_returns_db_records() {
        let conn = create_test_db();
        crate::db::save_workflow_run(&conn, "skill-a", "analytics", 3, "in_progress", "domain")
            .unwrap();
        crate::db::save_workflow_run(&conn, "skill-b", "marketing", 0, "pending", "platform")
            .unwrap();

        let skills = list_skills_inner("/unused", &conn).unwrap();
        assert_eq!(skills.len(), 2);

        // Find skill-a
        let a = skills.iter().find(|s| s.name == "skill-a").unwrap();
        assert_eq!(a.domain.as_deref(), Some("analytics"));
        assert_eq!(a.current_step.as_deref(), Some("Step 3"));
        assert_eq!(a.status.as_deref(), Some("in_progress"));
        assert_eq!(a.skill_type.as_deref(), Some("domain"));

        // Find skill-b
        let b = skills.iter().find(|s| s.name == "skill-b").unwrap();
        assert_eq!(b.domain.as_deref(), Some("marketing"));
        assert_eq!(b.current_step.as_deref(), Some("Step 0"));
        assert_eq!(b.status.as_deref(), Some("pending"));
        assert_eq!(b.skill_type.as_deref(), Some("platform"));
    }

    #[test]
    fn test_list_skills_db_primary_empty_db() {
        let conn = create_test_db();
        let skills = list_skills_inner("/unused", &conn).unwrap();
        assert!(skills.is_empty());
    }

    #[test]
    fn test_list_skills_db_primary_includes_tags() {
        let conn = create_test_db();
        crate::db::save_workflow_run(&conn, "tagged-skill", "sales", 2, "pending", "domain")
            .unwrap();
        crate::db::set_skill_tags(
            &conn,
            "tagged-skill",
            &["analytics".into(), "salesforce".into()],
        )
        .unwrap();

        let skills = list_skills_inner("/unused", &conn).unwrap();
        assert_eq!(skills.len(), 1);
        assert_eq!(skills[0].tags, vec!["analytics", "salesforce"]);
    }

    #[test]
    fn test_list_skills_db_primary_last_modified_from_db() {
        let conn = create_test_db();
        crate::db::save_workflow_run(&conn, "my-skill", "domain", 0, "pending", "domain").unwrap();

        let skills = list_skills_inner("/unused", &conn).unwrap();
        assert_eq!(skills.len(), 1);
        // last_modified should be populated from updated_at (not filesystem)
        assert!(skills[0].last_modified.is_some());
    }

    #[test]
    fn test_list_skills_db_primary_no_filesystem_access_needed() {
        // This test proves that list_skills_inner works without any filesystem
        // by using a nonexistent workspace path. The DB is the sole data source.
        let conn = create_test_db();
        crate::db::save_workflow_run(
            &conn,
            "no-disk-skill",
            "virtual",
            5,
            "completed",
            "source",
        )
        .unwrap();

        let skills =
            list_skills_inner("/this/path/does/not/exist/at/all", &conn).unwrap();
        assert_eq!(skills.len(), 1);
        assert_eq!(skills[0].name, "no-disk-skill");
        assert_eq!(skills[0].domain.as_deref(), Some("virtual"));
        assert_eq!(skills[0].current_step.as_deref(), Some("Step 5"));
    }

    #[test]
    fn test_list_skills_db_primary_sorted_by_last_modified_desc() {
        let conn = create_test_db();
        // Create skills with different updated_at by updating in sequence
        crate::db::save_workflow_run(&conn, "oldest", "d1", 0, "pending", "domain").unwrap();
        crate::db::save_workflow_run(&conn, "newest", "d2", 3, "in_progress", "domain").unwrap();

        let skills = list_skills_inner("/unused", &conn).unwrap();
        assert_eq!(skills.len(), 2);
        // The most recently updated should come first
        // Since they're created nearly simultaneously, just verify both exist
        let names: Vec<&str> = skills.iter().map(|s| s.name.as_str()).collect();
        assert!(names.contains(&"oldest"));
        assert!(names.contains(&"newest"));
    }

    // ===== create + list integration =====

    #[test]
    fn test_create_and_list_skills_db_primary() {
        let dir = tempdir().unwrap();
        let workspace = dir.path().to_str().unwrap();
        let conn = create_test_db();

        create_skill_inner(workspace, "my-skill", "sales pipeline", None, None, Some(&conn), None, None, None, "0.1.0", None)
            .unwrap();

        let skills = list_skills_inner(workspace, &conn).unwrap();
        assert_eq!(skills.len(), 1);
        assert_eq!(skills[0].name, "my-skill");
        assert_eq!(skills[0].domain.as_deref(), Some("sales pipeline"));
        assert_eq!(skills[0].status.as_deref(), Some("pending"));
    }

    #[test]
    fn test_create_duplicate_skill() {
        let dir = tempdir().unwrap();
        let workspace = dir.path().to_str().unwrap();

        create_skill_inner(workspace, "dup-skill", "domain", None, None, None, None, None, None, "0.1.0", None).unwrap();
        let result = create_skill_inner(workspace, "dup-skill", "domain", None, None, None, None, None, None, "0.1.0", None);
        assert!(result.is_err());
        assert!(result.unwrap_err().contains("already exists"));
    }

    // ===== delete_skill_inner tests =====

    #[test]
    fn test_delete_skill_workspace_only() {
        let dir = tempdir().unwrap();
        let workspace = dir.path().to_str().unwrap();
        let conn = create_test_db();

        create_skill_inner(workspace, "to-delete", "domain", None, None, Some(&conn), None, None, None, "0.1.0", None)
            .unwrap();

        let skills = list_skills_inner(workspace, &conn).unwrap();
        assert_eq!(skills.len(), 1);

        delete_skill_inner(workspace, "to-delete", Some(&conn), None).unwrap();

        // DB should be clean
        let skills = list_skills_inner(workspace, &conn).unwrap();
        assert_eq!(skills.len(), 0);

        // Filesystem should be clean
        assert!(!Path::new(workspace).join("to-delete").exists());
    }

    #[test]
    fn test_delete_skill_with_skills_path() {
        let dir = tempdir().unwrap();
        let workspace = dir.path().to_str().unwrap();
        let skills_dir = tempdir().unwrap();
        let skills_path = skills_dir.path().to_str().unwrap();
        let conn = create_test_db();

        // Create skill in workspace
        create_skill_inner(
            workspace,
            "full-delete",
            "domain",
            None,
            None,
            Some(&conn),
            Some(skills_path),
            None,
            None,
            "0.1.0",
            None,
        )
        .unwrap();

        // Simulate skill output in skills_path (as would happen after build step)
        let output_dir = Path::new(skills_path).join("full-delete");
        fs::create_dir_all(output_dir.join("references")).unwrap();
        fs::write(output_dir.join("SKILL.md"), "# Skill").unwrap();

        delete_skill_inner(workspace, "full-delete", Some(&conn), Some(skills_path)).unwrap();

        // Workspace dir should be gone
        assert!(!Path::new(workspace).join("full-delete").exists());
        // Skills output dir should be gone
        assert!(!output_dir.exists());
        // DB should be clean
        assert!(crate::db::get_workflow_run(&conn, "full-delete")
            .unwrap()
            .is_none());
    }

    #[test]
    fn test_delete_skill_cleans_db_fully() {
        let dir = tempdir().unwrap();
        let workspace = dir.path().to_str().unwrap();
        let conn = create_test_db();

        // Create skill with DB records
        create_skill_inner(
            workspace,
            "db-cleanup",
            "domain",
            Some(&["tag1".into(), "tag2".into()]),
            Some("platform"),
            Some(&conn),
            None,
            None,
            None,
            "0.1.0",
            None,
        )
        .unwrap();

        // Add workflow steps
        crate::db::save_workflow_step(&conn, "db-cleanup", 0, "completed").unwrap();

        // Add workflow artifact
        conn.execute(
            "INSERT INTO workflow_artifacts (skill_name, step_id, relative_path, content, size_bytes) VALUES ('db-cleanup', 0, 'test.md', '# Test', 6)",
            [],
        )
        .unwrap();

        // Add skill lock
        conn.execute(
            "INSERT INTO skill_locks (skill_name, instance_id, pid) VALUES ('db-cleanup', 'inst-1', 12345)",
            [],
        )
        .unwrap();

        delete_skill_inner(workspace, "db-cleanup", Some(&conn), None).unwrap();

        // Verify all DB records are cleaned up
        assert!(crate::db::get_workflow_run(&conn, "db-cleanup")
            .unwrap()
            .is_none());
        assert!(crate::db::get_workflow_steps(&conn, "db-cleanup")
            .unwrap()
            .is_empty());
        let tags = crate::db::get_tags_for_skills(&conn, &["db-cleanup".into()])
            .unwrap();
        assert!(tags.get("db-cleanup").is_none());

        // Verify workflow artifacts are cleaned up
        let artifact_count: i64 = conn
            .query_row(
                "SELECT COUNT(*) FROM workflow_artifacts WHERE skill_name = ?1",
                ["db-cleanup"],
                |row| row.get(0),
            )
            .unwrap();
        assert_eq!(artifact_count, 0);

        // Verify skill locks are cleaned up
        let lock_count: i64 = conn
            .query_row(
                "SELECT COUNT(*) FROM skill_locks WHERE skill_name = ?1",
                ["db-cleanup"],
                |row| row.get(0),
            )
            .unwrap();
        assert_eq!(lock_count, 0);
    }

    #[test]
    fn test_delete_skill_no_workspace_dir_but_has_skills_output() {
        // Skill may have been deleted from workspace but output still exists
        let dir = tempdir().unwrap();
        let workspace = dir.path().to_str().unwrap();
        let skills_dir = tempdir().unwrap();
        let skills_path = skills_dir.path().to_str().unwrap();
        let conn = create_test_db();

        // Only create skill output, no workspace dir
        let output_dir = Path::new(skills_path).join("orphan-output");
        fs::create_dir_all(output_dir.join("references")).unwrap();
        fs::write(output_dir.join("SKILL.md"), "# Skill").unwrap();

        // Add DB record
        crate::db::save_workflow_run(&conn, "orphan-output", "domain", 7, "completed", "domain")
            .unwrap();

        delete_skill_inner(workspace, "orphan-output", Some(&conn), Some(skills_path)).unwrap();

        // Skills output should be deleted
        assert!(!output_dir.exists());
        // DB should be clean
        assert!(crate::db::get_workflow_run(&conn, "orphan-output")
            .unwrap()
            .is_none());
    }

    #[test]
    fn test_delete_skill_no_workspace_dir_no_output() {
        // Neither workspace dir nor skills output exists — just DB cleanup
        let dir = tempdir().unwrap();
        let workspace = dir.path().to_str().unwrap();
        let conn = create_test_db();

        crate::db::save_workflow_run(&conn, "ghost", "domain", 3, "pending", "domain").unwrap();

        delete_skill_inner(workspace, "ghost", Some(&conn), None).unwrap();

        assert!(crate::db::get_workflow_run(&conn, "ghost")
            .unwrap()
            .is_none());
    }

    #[test]
    fn test_delete_skill_directory_traversal() {
        let dir = tempdir().unwrap();
        let workspace = dir.path().join("workspace");
        fs::create_dir_all(&workspace).unwrap();
        let workspace_str = workspace.to_str().unwrap();

        // Create a directory OUTSIDE the workspace that a traversal attack would target
        let outside_dir = dir.path().join("outside-target");
        fs::create_dir_all(&outside_dir).unwrap();

        // Create a symlink or sibling that the ".." traversal would resolve to
        // The workspace has a dir that resolves outside via ".."
        // workspace/legit is a real skill
        create_skill_inner(workspace_str, "legit", "domain", None, None, None, None, None, None, "0.1.0", None).unwrap();

        // Attempt to delete using ".." to escape the workspace
        // This creates workspace/../outside-target which resolves to outside_dir
        let result = delete_skill_inner(workspace_str, "../outside-target", None, None);
        assert!(result.is_err(), "Directory traversal should be rejected");

        // The outside directory should still exist (not deleted)
        assert!(outside_dir.exists());
        // The legitimate skill should still exist
        assert!(workspace.join("legit").exists());
    }

    #[test]
    fn test_delete_skill_nonexistent_is_noop() {
        // When neither workspace dir nor skills output nor DB record exists,
        // delete should succeed as a no-op
        let dir = tempdir().unwrap();
        let workspace = dir.path().to_str().unwrap();

        let result = delete_skill_inner(workspace, "no-such-skill", None, None);
        assert!(result.is_ok());
    }

    // ===== Existing tests (updated signatures) =====

    #[test]
    fn test_create_skill_collision_in_workspace() {
        let dir = tempdir().unwrap();
        let workspace = dir.path().to_str().unwrap();
        let skills_dir = tempdir().unwrap();
        let skills_path = skills_dir.path().to_str().unwrap();

        // Create the skill directory in workspace manually (simulating a pre-existing dir)
        fs::create_dir_all(Path::new(workspace).join("colliding-skill")).unwrap();

        let result = create_skill_inner(
            workspace,
            "colliding-skill",
            "domain",
            None,
            None,
            None,
            Some(skills_path),
            None,
            None,
            "0.1.0",
            None,
        );
        assert!(result.is_err());
        let err = result.unwrap_err();
        assert!(err.contains("already exists"), "Error should mention 'already exists': {}", err);
        assert!(err.contains("workspace directory"), "Error should mention 'workspace directory': {}", err);
    }

    #[test]
    fn test_create_skill_collision_in_skills_path() {
        let dir = tempdir().unwrap();
        let workspace = dir.path().to_str().unwrap();
        let skills_dir = tempdir().unwrap();
        let skills_path = skills_dir.path().to_str().unwrap();

        // Create the skill directory in skills_path manually (simulating a pre-existing output dir)
        fs::create_dir_all(Path::new(skills_path).join("colliding-skill")).unwrap();

        let result = create_skill_inner(
            workspace,
            "colliding-skill",
            "domain",
            None,
            None,
            None,
            Some(skills_path),
            None,
            None,
            "0.1.0",
            None,
        );
        assert!(result.is_err());
        let err = result.unwrap_err();
        assert!(err.contains("already exists"), "Error should mention 'already exists': {}", err);
        assert!(err.contains("skills output directory"), "Error should mention 'skills output directory': {}", err);
    }

    #[test]
    fn test_create_skill_no_collision() {
        let dir = tempdir().unwrap();
        let workspace = dir.path().to_str().unwrap();
        let skills_dir = tempdir().unwrap();
        let skills_path = skills_dir.path().to_str().unwrap();

        // Neither workspace nor skills_path has the skill directory
        let result = create_skill_inner(
            workspace,
            "new-skill",
            "test domain",
            None,
            None,
            None,
            Some(skills_path),
            None,
            None,
            "0.1.0",
            None,
        );
        assert!(result.is_ok());

        // Verify the workspace working directory was created
        assert!(Path::new(workspace).join("new-skill").exists());

        // Verify skill output directories were created in skills_path
        let skill_output = Path::new(skills_path).join("new-skill");
        assert!(skill_output.join("context").exists());
        assert!(skill_output.join("references").exists());
    }

    #[test]
    fn test_delete_skill_removes_logs_directory() {
        let dir = tempdir().unwrap();
        let workspace = dir.path().to_str().unwrap();

        // Create a skill
        create_skill_inner(workspace, "skill-with-logs", "analytics", None, None, None, None, None, None, "0.1.0", None).unwrap();

        // Add a logs/ subdirectory with a fake log file inside the skill directory
        let skill_dir = dir.path().join("skill-with-logs");
        let logs_dir = skill_dir.join("logs");
        fs::create_dir_all(&logs_dir).unwrap();
        fs::write(logs_dir.join("step-0.log"), "fake log content for step 0").unwrap();
        fs::write(logs_dir.join("step-1.log"), "fake log content for step 1").unwrap();

        // Verify the logs directory and files exist before deletion
        assert!(logs_dir.exists());
        assert!(logs_dir.join("step-0.log").exists());
        assert!(logs_dir.join("step-1.log").exists());

        // Delete the skill
        delete_skill_inner(workspace, "skill-with-logs", None, None).unwrap();

        // Verify the entire skill directory (including logs/) is gone
        assert!(!skill_dir.exists(), "skill directory should be removed");
        assert!(!logs_dir.exists(), "logs directory should be removed");
    }

    // ===== update_skill_metadata tests =====

    /// Helper: create a skill in the DB for metadata update tests.
    fn setup_skill_for_metadata(conn: &Connection, name: &str) {
        crate::db::save_workflow_run(conn, name, "analytics", 0, "pending", "domain").unwrap();
    }

    #[test]
    fn test_update_metadata_display_name() {
        let conn = create_test_db();
        setup_skill_for_metadata(&conn, "meta-skill");

        crate::db::set_skill_display_name(&conn, "meta-skill", Some("Pretty Name")).unwrap();

        let row = crate::db::get_workflow_run(&conn, "meta-skill").unwrap().unwrap();
        assert_eq!(row.display_name.as_deref(), Some("Pretty Name"));
    }

    #[test]
    fn test_update_metadata_skill_type() {
        let conn = create_test_db();
        setup_skill_for_metadata(&conn, "type-skill");

        conn.execute(
            "UPDATE workflow_runs SET skill_type = ?2, updated_at = datetime('now') || 'Z' WHERE skill_name = ?1",
            rusqlite::params!["type-skill", "platform"],
        ).unwrap();

        let row = crate::db::get_workflow_run(&conn, "type-skill").unwrap().unwrap();
        assert_eq!(row.skill_type, "platform");
    }

    #[test]
    fn test_update_metadata_tags() {
        let conn = create_test_db();
        setup_skill_for_metadata(&conn, "tag-skill");

        crate::db::set_skill_tags(&conn, "tag-skill", &["rust".into(), "wasm".into()]).unwrap();

        let tags = crate::db::get_tags_for_skills(&conn, &["tag-skill".into()]).unwrap();
        assert_eq!(tags.get("tag-skill").unwrap(), &["rust", "wasm"]);
    }

    #[test]
    fn test_update_metadata_intake_json() {
        let conn = create_test_db();
        setup_skill_for_metadata(&conn, "intake-skill");

        let json = r#"{"audience":"Engineers","challenges":"Scale","scope":"Backend"}"#;
        crate::db::set_skill_intake(&conn, "intake-skill", Some(json)).unwrap();

        let row = crate::db::get_workflow_run(&conn, "intake-skill").unwrap().unwrap();
        assert_eq!(row.intake_json.as_deref(), Some(json));
    }

    #[test]
    fn test_update_metadata_all_fields() {
        let conn = create_test_db();
        setup_skill_for_metadata(&conn, "full-meta");

        // Update all four fields as update_skill_metadata would
        crate::db::set_skill_display_name(&conn, "full-meta", Some("Full Metadata")).unwrap();
        conn.execute(
            "UPDATE workflow_runs SET skill_type = ?2, updated_at = datetime('now') || 'Z' WHERE skill_name = ?1",
            rusqlite::params!["full-meta", "source"],
        ).unwrap();
        crate::db::set_skill_tags(&conn, "full-meta", &["api".into(), "rest".into()]).unwrap();
        crate::db::set_skill_intake(&conn, "full-meta", Some(r#"{"audience":"Devs"}"#)).unwrap();

        let row = crate::db::get_workflow_run(&conn, "full-meta").unwrap().unwrap();
        assert_eq!(row.display_name.as_deref(), Some("Full Metadata"));
        assert_eq!(row.skill_type, "source");
        assert_eq!(row.intake_json.as_deref(), Some(r#"{"audience":"Devs"}"#));

        let tags = crate::db::get_tags_for_skills(&conn, &["full-meta".into()]).unwrap();
        assert_eq!(tags.get("full-meta").unwrap(), &["api", "rest"]);
    }

    // ===== list_refinable_skills_inner tests =====

    #[test]
    fn test_list_refinable_skills_returns_only_completed_with_skill_md() {
        let dir = tempdir().unwrap();
        let skills_path = dir.path().to_str().unwrap();
        let conn = create_test_db();

        // Create a completed skill with SKILL.md on disk
        crate::db::save_workflow_run(&conn, "ready-skill", "analytics", 7, "completed", "domain")
            .unwrap();
        let skill_dir = dir.path().join("ready-skill");
        fs::create_dir_all(&skill_dir).unwrap();
        fs::write(skill_dir.join("SKILL.md"), "# Ready").unwrap();

        // Create an in-progress skill (should be excluded)
        crate::db::save_workflow_run(
            &conn,
            "wip-skill",
            "marketing",
            3,
            "in_progress",
            "domain",
        )
        .unwrap();

        let result = list_refinable_skills_inner("/unused", skills_path, &conn).unwrap();
        assert_eq!(result.len(), 1);
        assert_eq!(result[0].name, "ready-skill");
    }

    #[test]
    fn test_list_refinable_skills_excludes_completed_without_skill_md() {
        let dir = tempdir().unwrap();
        let skills_path = dir.path().to_str().unwrap();
        let conn = create_test_db();

        // Completed in DB but no SKILL.md on disk
        crate::db::save_workflow_run(&conn, "no-file", "domain", 7, "completed", "domain")
            .unwrap();

        let result = list_refinable_skills_inner("/unused", skills_path, &conn).unwrap();
        assert!(result.is_empty());
    }

    #[test]
    fn test_list_refinable_skills_empty_db() {
        let dir = tempdir().unwrap();
        let skills_path = dir.path().to_str().unwrap();
        let conn = create_test_db();

        let result = list_refinable_skills_inner("/unused", skills_path, &conn).unwrap();
        assert!(result.is_empty());
    }

    #[test]
    fn test_update_metadata_nonexistent_skill_is_noop() {
        let conn = create_test_db();

        // These should succeed (UPDATE affects 0 rows, no error)
        crate::db::set_skill_display_name(&conn, "ghost", Some("Name")).unwrap();
        crate::db::set_skill_tags(&conn, "ghost", &["tag".into()]).unwrap();
        crate::db::set_skill_intake(&conn, "ghost", Some("{}")).unwrap();

        // No row should exist
        assert!(crate::db::get_workflow_run(&conn, "ghost").unwrap().is_none());
    }

    // ===== rename_skill tests =====

    /// Helper: save skills_path into the settings table so rename_skill_inner
    /// can read it via `crate::db::read_settings`.
    fn save_skills_path_setting(conn: &Connection, skills_path: &str) {
        let settings = crate::types::AppSettings {
            skills_path: Some(skills_path.to_string()),
            ..Default::default()
        };
        crate::db::write_settings(conn, &settings).unwrap();
    }

    #[test]
    fn test_rename_skill_basic() {
        let workspace_dir = tempdir().unwrap();
        let workspace = workspace_dir.path().to_str().unwrap();
        let skills_dir = tempdir().unwrap();
        let skills_path = skills_dir.path().to_str().unwrap();
        let conn = create_test_db();
        save_skills_path_setting(&conn, skills_path);

        // Create skill with workspace dir, skills dir, DB record, tags, and steps
        create_skill_inner(
            workspace, "old-name", "analytics",
            Some(&["tag-a".into(), "tag-b".into()]),
            Some("domain"), Some(&conn), Some(skills_path),
            None, None, "0.1.0", None,
        ).unwrap();
        crate::db::save_workflow_step(&conn, "old-name", 0, "completed").unwrap();

        // Rename
        rename_skill_inner("old-name", "new-name", workspace, &conn, Some(skills_path)).unwrap();

        // Workspace dirs moved
        assert!(!Path::new(workspace).join("old-name").exists());
        assert!(Path::new(workspace).join("new-name").exists());

        // Skills dirs moved
        assert!(!Path::new(skills_path).join("old-name").exists());
        assert!(Path::new(skills_path).join("new-name").exists());

        // DB: old record gone, new record present with same data
        assert!(crate::db::get_workflow_run(&conn, "old-name").unwrap().is_none());
        let row = crate::db::get_workflow_run(&conn, "new-name").unwrap().unwrap();
        assert_eq!(row.domain, "analytics");
        assert_eq!(row.skill_type, "domain");

        // Tags migrated
        let tags = crate::db::get_tags_for_skills(&conn, &["new-name".into()]).unwrap();
        let new_tags = tags.get("new-name").unwrap();
        assert!(new_tags.contains(&"tag-a".to_string()));
        assert!(new_tags.contains(&"tag-b".to_string()));
        // Old tags gone
        let old_tags = crate::db::get_tags_for_skills(&conn, &["old-name".into()]).unwrap();
        assert!(old_tags.get("old-name").is_none());

        // Workflow steps migrated
        let steps = crate::db::get_workflow_steps(&conn, "new-name").unwrap();
        assert_eq!(steps.len(), 1);
        let old_steps = crate::db::get_workflow_steps(&conn, "old-name").unwrap();
        assert!(old_steps.is_empty());
    }

    #[test]
    fn test_rename_skill_invalid_kebab_case() {
        // The kebab-case validation happens in the Tauri command wrapper (rename_skill),
        // not in rename_skill_inner, so we test the validation logic directly.
        let invalid_names = vec![
            "HasUpperCase",
            "has spaces",
            "-leading-hyphen",
            "trailing-hyphen-",
            "double--hyphen",
            "",
            "ALLCAPS",
            "under_score",
        ];

        for name in invalid_names {
            assert!(
                !is_valid_kebab(name),
                "Name '{}' should be rejected as non-kebab-case",
                name
            );
        }

        // Valid kebab-case names should pass
        let valid_names = vec!["my-skill", "a", "skill-123", "a-b-c"];
        for name in valid_names {
            assert!(
                is_valid_kebab(name),
                "Name '{}' should be accepted as valid kebab-case",
                name
            );
        }
    }

    #[test]
    fn test_rename_skill_collision() {
        let workspace_dir = tempdir().unwrap();
        let workspace = workspace_dir.path().to_str().unwrap();
        let conn = create_test_db();

        // Create two skills in DB
        create_skill_inner(workspace, "skill-a", "domain-a", None, None, Some(&conn), None, None, None, "0.1.0", None).unwrap();
        create_skill_inner(workspace, "skill-b", "domain-b", None, None, Some(&conn), None, None, None, "0.1.0", None).unwrap();

        // Attempt to rename skill-a to skill-b (collision)
        let result = rename_skill_inner("skill-a", "skill-b", workspace, &conn, None);
        assert!(result.is_err());
        let err = result.unwrap_err();
        assert!(err.contains("already exists"), "Error should mention collision: {}", err);

        // Original skill should be untouched
        let row = crate::db::get_workflow_run(&conn, "skill-a").unwrap().unwrap();
        assert_eq!(row.domain, "domain-a");
    }

    #[test]
    fn test_rename_skill_noop_same_name() {
        // When old == new, the Tauri command returns Ok(()) without touching DB.
        // Since rename_skill_inner is only called when old != new, we test the
        // early-return logic that lives in the command wrapper.
        let old = "same-name";
        let new = "same-name";
        assert_eq!(old, new);
        // The command returns Ok(()) for this case — verified by the condition.
        // We also verify rename_skill_inner would work if called (same name = collision in DB).
        let conn = create_test_db();
        let workspace_dir = tempdir().unwrap();
        let workspace = workspace_dir.path().to_str().unwrap();
        create_skill_inner(workspace, "same-name", "domain", None, None, Some(&conn), None, None, None, "0.1.0", None).unwrap();

        // rename_skill_inner with same name hits the "already exists" check in DB,
        // confirming the early-return in the wrapper is necessary.
        let result = rename_skill_inner("same-name", "same-name", workspace, &conn, None);
        assert!(result.is_err());
        assert!(result.unwrap_err().contains("already exists"));
    }

    #[test]
    fn test_rename_skill_disk_rollback_on_db_failure() {
        let workspace_dir = tempdir().unwrap();
        let workspace = workspace_dir.path().to_str().unwrap();
        let conn = create_test_db();

        // Create the skill on disk (workspace dir) and in DB
        create_skill_inner(workspace, "will-rollback", "analytics", None, None, Some(&conn), None, None, None, "0.1.0", None).unwrap();
        assert!(Path::new(workspace).join("will-rollback").exists());

        // To force the DB transaction to fail, we drop the workflow_runs table
        // after creating the skill, so the INSERT in the transaction will fail.
        // But we need the existence check to pass first (no row for "new-name").
        // Strategy: drop and recreate workflow_runs without the old row data columns,
        // so the INSERT...SELECT fails due to column mismatch.
        //
        // Simpler approach: insert a row with the new name AFTER the existence check
        // runs but before the transaction. Since we can't do that with a single call,
        // we instead corrupt the table structure.
        //
        // Simplest: drop the workflow_runs table entirely after the existence check.
        // But rename_skill_inner does the check and the tx in one call.
        //
        // Best approach: rename to a name that will fail in the INSERT because the
        // source row doesn't exist (i.e., old_name doesn't exist in DB, so
        // INSERT...SELECT copies 0 rows, then DELETE affects 0 rows, then the other
        // UPDATEs also affect 0 rows — that actually succeeds).
        //
        // Real approach: We need to make the transaction fail. We can do this by
        // creating a trigger that raises an error, or by making the table read-only.
        // The easiest: add a UNIQUE constraint violation by pre-inserting the new name
        // into a table that the transaction will try to UPDATE into.
        //
        // Actually, the cleanest way: put a row in workflow_steps with the NEW name
        // and a UNIQUE constraint, but workflow_steps PK is (skill_name, step_id) so
        // we need a conflicting row. Let's add a step for "rollback-target" (the new name)
        // with the same step_id that "will-rollback" has after the UPDATE tries to set it.
        //
        // The transaction first does INSERT+DELETE on workflow_runs (succeeds), then
        // UPDATE workflow_steps. If we pre-insert a workflow_steps row with
        // (skill_name="rollback-target", step_id=0), the UPDATE from
        // (skill_name="will-rollback", step_id=0) to (skill_name="rollback-target", step_id=0)
        // will violate the PK and fail.
        crate::db::save_workflow_step(&conn, "will-rollback", 0, "completed").unwrap();
        // Pre-insert a conflicting row for the new name
        conn.execute(
            "INSERT INTO workflow_steps (skill_name, step_id, status) VALUES ('rollback-target', 0, 'pending')",
            [],
        ).unwrap();

        let result = rename_skill_inner("will-rollback", "rollback-target", workspace, &conn, None);
        assert!(result.is_err(), "Rename should fail due to DB constraint violation");
        assert!(result.unwrap_err().contains("Failed to rename skill in database"));

        // Workspace dir should be rolled back to original name
        assert!(
            Path::new(workspace).join("will-rollback").exists(),
            "Workspace dir should be rolled back to original name"
        );
        assert!(
            !Path::new(workspace).join("rollback-target").exists(),
            "New workspace dir should not exist after rollback"
        );

        // DB should still have the original skill
        let row = crate::db::get_workflow_run(&conn, "will-rollback");
        // The transaction was rolled back, but the INSERT+DELETE on workflow_runs
        // may have partially committed before the ROLLBACK. Let's check what we have.
        // Actually, since the transaction used BEGIN...COMMIT and the closure returned Err,
        // the outer code calls ROLLBACK, so all changes within the transaction are undone.
        // However, the INSERT of "rollback-target" into workflow_runs succeeded before
        // the workflow_steps UPDATE failed. The ROLLBACK undoes the entire transaction.
        // So the original "will-rollback" row should still exist.
        assert!(row.unwrap().is_some(), "Original DB row should survive after rollback");
    }
}
