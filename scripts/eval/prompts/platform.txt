Design a silver-layer incremental model in dbt that processes daily transaction data from a bronze raw events table into a cleaned, deduplicated transactions fact table. The model should handle late-arriving records (events that arrive 2-3 days after the transaction date), implement idempotency (running multiple times for the same date produces the same result), and maintain audit columns (loaded_at, updated_at). Include a comprehensive testing strategy with unit tests for deduplication logic, data quality tests (not_null on transaction_id, unique on transaction_id + date, relationships to dim_customer), and a data contract that enforces schema expectations (required columns, data types, acceptable value ranges). How should you structure the incremental logic to handle backfills, test edge cases like transactions with null amounts or future dates, and ensure the model can recover from partial failures?
---
Implement a data contract framework in dbt for a silver-layer customer dimension that enforces schema stability and data quality rules across upstream and downstream dependencies. Define the contract specification (required columns: customer_id, customer_name, email, created_at; data types; nullability constraints; freshness SLA of 24 hours), validation mechanisms (pre-hook checks that fail the build if upstream bronze data violates contracts, post-hook assertions that validate output quality), and contract versioning strategy (how to handle adding new columns vs changing existing column types). How should the contract handle breaking changes from upstream sources, what happens when a downstream gold model depends on a column you want to deprecate, and how do you test contract enforcement in CI/CD before deploying to production?
---
Build a comprehensive unit testing suite for a dbt silver model that calculates customer lifetime value (CLV) from bronze order and payment data. Use dbt-unit-testing or similar tools to create fixture data (mock orders, payments, refunds), mock upstream dependencies (dim_customer, dim_product), and assert expected CLV calculations for various scenarios: new customer with single order, repeat customer with multiple orders, customer with refunds, customer with partial payments. Include edge case tests (null payment amounts, orders with zero value, customers with only refunds, date boundary conditions like year-end). How should unit tests integrate with dbt's built-in data tests, what's the right balance between fast unit tests and slower integration tests, and how do you maintain test fixtures as the model evolves?
---
Design a reusable testing macro library in dbt that standardizes data quality checks for silver and gold models across your analytics project. Create macros for common patterns: referential integrity tests across time-partitioned tables (ensuring foreign keys exist in dimension tables for all partition dates), SCD Type 2 validity checks (no overlapping valid_from/valid_to ranges, no gaps in history), metric reconciliation between fact and aggregate tables (sum of daily facts equals monthly aggregate), and PII detection (flag columns containing emails, phone numbers, SSNs). Package these macros with documentation, usage examples, and configuration options (severity levels, custom error messages). How should the macros handle different warehouse dialects (Snowflake vs BigQuery vs Redshift), version compatibility with dbt core, and extensibility for project-specific test patterns?
---
Implement a CI/CD deployment strategy for dbt that ensures comprehensive test coverage before promoting silver and gold models to production. Define pipeline stages: lint/format checks (sqlfluff, sqlfmt), unit test execution (dbt-unit-testing), slim CI for modified models only (dbt build --select state:modified+), full regression testing (all models and tests), and blue-green deployment with canary analysis (deploy to staging, run smoke tests, gradually shift traffic). Set test coverage requirements (minimum 80% of models have tests, all silver models require unit tests, all gold models require reconciliation tests), and define rollback procedures for failed deployments. How should you handle testing in ephemeral development environments, manage test data fixtures in version control, and balance test execution time (slim CI runs in <5 min) against coverage completeness?
